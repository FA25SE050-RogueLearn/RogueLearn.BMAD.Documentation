# **Story 1.9: AI Tagging for Notes (raw text & file upload)**

## Status

Draft

## Story

**As a** student/player,
**I want** the system to automatically suggest relevant tags when I create a note from raw text or by uploading files (PDF/DOCX/TXT), leveraging an AI pipeline (Semantic Kernel orchestrating Gemini),
**so that** my notes are consistently organized and easily discoverable without manual tagging effort.

## Acceptance Criteria

1. Tag Suggestion & Confirmation
   - When creating or updating a note, the system produces 3–7 tag suggestions with confidence scores and a rationale for each.
   - Suggestions clearly indicate whether a tag already exists in my personal catalog (existing) or is proposed as new (requires approval).
   - I can accept/reject individual suggestions; accepted existing tags are attached to the note, and accepted new tags are created in my tag catalog and then attached.
2. File Extraction & Processing Modes
   - For uploads (PDF/DOCX/TXT), the system extracts text and normalizes content; long inputs may be chunked.
   - Small inputs (< ~2k chars) return suggestions synchronously (< 3s). Larger inputs are processed asynchronously and return a job identifier.
3. API Endpoints
   - `POST /ai/tagging/suggest` accepts `{ userId, noteId? | content, existingTags? , options{ maxSuggestions, confidenceThreshold } }` and returns suggestions with `{ label, isExisting, matchTagId?, confidence, rationale }` and `{ mode: 'sync'|'async', jobId? }`.
   - `POST /ai/tagging/commit` accepts `{ userId, noteId, selections[] }` and applies accepted tags; new tags are created only if approved.
4. Validation & Error Handling
   - Empty content or unsupported file formats are rejected with friendly errors (400); extraction failures surface actionable messages.
   - Rate limiting per user prevents abuse; AI unavailability degrades gracefully (optional keyword-based fallback if enabled).
   - Privacy-aware logging: store minimal AI metadata (model, prompt version, confidence) without leaking sensitive note content.
5. Documentation
   - OpenAPI docs for both endpoints (`/ai/tagging/suggest`, `/ai/tagging/commit`) including request/response schemas and error models.
6. Testing
   - Integration tests using WebApplicationFactory + TestContainers (PostgreSQL) with a stubbed SK/Gemini provider to produce deterministic suggestions.
   - Scenarios cover raw text, file uploads, existing tag mapping, new tag approval flow, async processing for large inputs, and error cases.

## Tasks / Subtasks

- [ ] Task 1: Domain & Data Models Alignment
  - [ ] Confirm and/or add tables: `tags` (per-user), `note_tags` (join), `tag_suggestions` (transient/record of AI output) in User Service DB.
  - [ ] Enforce tag normalization (lowercase, trimmed), uniqueness per user, and slug generation.
- [ ] Task 2: AI Pipeline (Semantic Kernel + Gemini)
  - [ ] Implement preprocessing (language detection, normalization, chunking) and optional summarization for long inputs.
  - [ ] Prompt design for candidate topics/keywords with confidence; map to existing tags via semantic similarity/fuzzy matching.
  - [ ] Propose canonical new tag names when no suitable existing tag matches and confidence surpasses threshold.
- [ ] Task 3: Services & Controllers
  - [ ] `TaggingSuggestionService` (or module) to orchestrate suggestion and commit flows.
  - [ ] Implement endpoints: `POST /ai/tagging/suggest` and `POST /ai/tagging/commit` with JWT validation and RBAC.
  - [ ] Commit flow creates approved new tags and attaches accepted tags to the note via `note_tags`.
- [ ] Task 4: File Extraction
  - [ ] Implement text extraction for PDF/DOCX/TXT and error handling; chunk large files.
  - [ ] Switch to async processing for large inputs and provide job identifiers (status endpoint may be defined in a future story).
- [ ] Task 5: Error Handling, Security, & Cost Control
  - [ ] Centralized error responses; rate limiting; minimal metadata logging; configurable token caps for AI requests.
- [ ] Task 6: OpenAPI & CI
  - [ ] Document suggest/commit endpoints and schemas; validate in CI.
- [ ] Task 7: Testing
  - [ ] Integration and negative tests; acceptance flow tests (existing vs new tags, approvals, async mode).

## Dev Notes

### Ownership & Architecture
- Personal notes and tagging catalogs are owned by the User Service; other services consume via User Service APIs.
- AI tagging can be implemented as an internal module within User Service or delegated to an internal AI service; ensure per-user isolation and vocabulary preference.
- Delegation pattern: any `/notes` integration in other services must call User Service; tag storage stays centralized in User Service.

### Data Model (User Service)
- Tables: `notes`, `tags` (per-user catalog), `note_tags` (join), `tag_suggestions` (record suggestions for audit/UX).
- Indexes: `idx_tags_auth_user_id`, `idx_note_tags_note_id`, `idx_note_tags_tag_id`; ensure fast lookup and mapping.
- Normalization: lowercase labels, unique per-user, slug generation, optional synonyms.

### AI Tagging Pipeline (SK + Gemini)
- Steps: preprocess → summarize (optional) → candidate extraction → map to existing tags (semantic similarity) → propose new tags (above threshold) → deduplicate/diversify → return suggestions with confidence and rationale.
- Configuration: temperature 0.2–0.5; token caps; multilingual support; max suggestions default 10; confidenceThreshold default 0.55.

### Security & Privacy
- JWT validation (Story 1.2); owner-only tag operations.
- Minimal logging of AI outputs; redact sensitive content; rate limit requests per user.
- New tag creation requires explicit user approval to prevent tag explosion.

### UI/UX Context
- Frontend presents suggestions with confidence and badges for existing vs new; user can approve/reject and optionally rename proposed new tags.
- This story focuses on backend/API; detailed frontend interactions will be covered in a future story.

### Testing Strategy
- WebApplicationFactory + TestContainers (PostgreSQL) for end-to-end.
- Stub SK/Gemini for deterministic outputs; cover raw text, uploads, mapping, approvals, and async path.

### Sources & References
- `docs/stories/story-1/1.8.notes-management.md` (Notes CRUD and tag attach/detach)
- `docs/fullstack-architecture/api-specification.md`
- `docs/prd/technical-guidance.md`

## Change Log

| Date | Version | Description | Author |
| :--- | :--- | :--- | :--- |
| [Current Date] | 1.0 | Initial story draft | Bob, SM |

## Dev Agent Record

### Agent Model Used
_TBD by Dev Agent_

### Debug Log References
_TBD by Dev Agent_

### Completion Notes List
_TBD by Dev Agent_

### File List
_TBD by Dev Agent_

## QA Results
_TBD by QA Agent_